# C++ Unit Test Generator with LLM

A sophisticated automated unit test generation system for C++ projects using Large Language Models (LLMs) with strict YAML-based instructions. This tool generates, refines, and validates unit tests while providing comprehensive test coverage analysis.

## üöÄ Features

- **Automated Test Generation**: Uses LLM to generate initial unit tests for C++ source files
- **Intelligent Test Refinement**: Removes duplicates, improves coverage, and enhances test quality
- **Build Integration**: Automatically builds projects and handles compilation errors
- **Coverage Analysis**: Integrates with GNU code coverage tools (gcov/lcov)
- **YAML-Based Instructions**: Strict, repeatable prompts for consistent test generation
- **Error Recovery**: Handles build failures and provides fix suggestions
- **Cross-Platform**: Works on Windows, Linux, and macOS

## üìã Requirements

### System Requirements

- **Python 3.7+**
- **C++ Compiler** (GCC, Clang, or MSVC)
- **CMake 3.10+**
- **Google Test Framework**
- **GNU Coverage Tools** (gcov, lcov)

### LLM Requirements

- **Ollama** running locally on `localhost:11434`
- **Recommended Models**: `phi3:mini`, `llama3.2`, or `codellama`

### Python Dependencies

```
requests>=2.25.0
```

## üõ†Ô∏è Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd cpp-unit-test-gen
```

### 2. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 3. Install System Dependencies

#### Windows

```bash
# Install Visual Studio Build Tools or MinGW
# Install CMake from https://cmake.org/download/
# Install Google Test (vcpkg recommended)
vcpkg install gtest
```

#### Linux (Ubuntu/Debian)

```bash
sudo apt update
sudo apt install build-essential cmake libgtest-dev lcov
```

#### macOS

```bash
# Install Xcode Command Line Tools
xcode-select --install

# Install dependencies via Homebrew
brew install cmake googletest lcov
```

### 4. Setup Ollama

```bash
# Install Ollama (https://ollama.ai/)
# Pull a suitable model
ollama pull phi3:mini
# Start Ollama service
ollama serve
```

## üìÅ Project Structure

```
cpp-unit-test-gen/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Main orchestration script
‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py        # LLM API client
‚îÇ   ‚îú‚îÄ‚îÄ build_utils.py       # Build and coverage utilities
‚îÇ   ‚îî‚îÄ‚îÄ yaml_prompts/        # YAML instruction files
‚îÇ       ‚îú‚îÄ‚îÄ initial.yaml     # Initial test generation prompts
‚îÇ       ‚îú‚îÄ‚îÄ refine.yaml      # Test refinement prompts
‚îÇ       ‚îî‚îÄ‚îÄ fix_build.yaml   # Build error fix prompts
‚îú‚îÄ‚îÄ test_projects/           # Input C++ projects
‚îÇ   ‚îî‚îÄ‚îÄ orgChartApi-master/  # Sample project
‚îú‚îÄ‚îÄ generated_tests/         # Output test files
‚îú‚îÄ‚îÄ build/                   # Build artifacts
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îî‚îÄ‚îÄ README.md               # This file
```

## üéØ Usage

### Basic Usage

1. **Place your C++ project** in the `test_projects/` directory
2. **Run the test generation pipeline**:
   ```bash
   python src/main.py
   ```

### Advanced Usage

#### Custom Project Path

Modify the `project_dir` variable in `src/main.py`:

```python
project_dir = os.path.join(project_root, "test_projects", "your-project-name")
```

#### Different LLM Model

Change the model in `src/llm_client.py`:

```python
def call_llm(prompt, model="llama3.2", max_retries=3):
```

#### Custom YAML Prompts

Edit the YAML files in `src/yaml_prompts/` to customize:

- Test generation style
- Framework preferences
- Coverage requirements
- Error handling strategies

## üîß Configuration

### YAML Prompt Files

#### `initial.yaml` - Initial Test Generation

```yaml
task: generate_unit_tests
framework: gtest
requirements:
  - No duplicate tests
  - Add all necessary #include statements
  - Use Google Test best practices
  - One test file per input file
  - Format code strictly
  - Maximize code coverage
```

#### `refine.yaml` - Test Refinement

```yaml
task: refine_unit_tests
requirements:
  - Remove duplicate or redundant tests
  - Add missing includes or libraries
  - Improve test coverage and formatting
  - No test should be repeated
  - Use Google Test idioms
```

#### `fix_build.yaml` - Build Error Fixes

```yaml
task: fix_build_errors
requirements:
  - Analyze build error messages and identify root causes
  - Fix missing includes, libraries, or dependencies
  - Correct syntax errors, typos, or compilation issues
  - Ensure proper CMake configuration and linking
  - Provide specific fixes for each error identified
  - Maintain Google Test framework compatibility
```

### Environment Variables

```bash
# Optional: Override default Ollama URL
export OLLAMA_API_URL="http://localhost:11434/api/generate"

# Optional: Set default model
export OLLAMA_MODEL="phi3:mini"
```

## üîÑ Pipeline Process

The tool follows a 4-step pipeline:

### Step 1: Initial Test Generation

1. **Scans** the C++ project for source files (`.cc`, `.cpp`)
2. **Sends** each file to the LLM with `initial.yaml` instructions
3. **Generates** initial unit tests in `generated_tests/` directory

### Step 2: Test Refinement

1. **Processes** generated test files
2. **Removes** duplicate tests
3. **Improves** test coverage and formatting
4. **Adds** missing includes and libraries

### Step 3: Build and Debug

1. **Attempts** to build the project with generated tests
2. **Handles** build errors automatically
3. **Sends** error logs to LLM for fixes
4. **Iterates** until build succeeds

### Step 4: Coverage Analysis

1. **Runs** the test suite
2. **Generates** coverage reports using gcov/lcov
3. **Outputs** HTML coverage report
4. **Provides** coverage statistics

## üìä Output

### Generated Files

- **Test Files**: `generated_tests/test_*.cc`
- **Build Artifacts**: `build/` directory
- **Coverage Report**: `build/coverage/index.html`

### Sample Output

```
üöÄ Starting C++ Unit Test Generation Pipeline
üìÅ Project directory: C:\cpp-unit-test-gen\test_projects\orgChartApi-master
üìÅ Test directory: C:\cpp-unit-test-gen\generated_tests
üìÅ Build directory: C:\cpp-unit-test-gen\build

üìù Step 1: Generating initial unit tests...
Found 16 C++ files to process:
  - main.cc
  - controllers/AuthController.cc
  - controllers/DepartmentsController.cc
  ...

‚úÖ Generated test: test_main.cc
‚úÖ Generated test: test_AuthController.cc
...

üîß Step 2: Refining generated tests...
‚úÖ Refined test: test_main.cc
‚úÖ Refined test: test_AuthController.cc
...

üî® Step 3: Building project with generated tests...
‚úÖ Build successful!

üß™ Step 4: Running tests and generating coverage...
‚úÖ Tests passed!
üìä Coverage report generated at: build/coverage/index.html

üéâ Pipeline completed!
```

## üêõ Troubleshooting

### Common Issues

#### 1. LLM Connection Errors

```
‚ùå Error: Failed to connect to Ollama
```

**Solution**: Ensure Ollama is running:

```bash
ollama serve
```

#### 2. Build Failures

```
‚ùå Build failed: CMake Error
```

**Solution**: Check CMake configuration and dependencies:

```bash
# Verify CMake installation
cmake --version

# Check if Google Test is available
find /usr -name "gtest" 2>/dev/null
```

#### 3. Coverage Tool Issues

```
‚ùå Error generating coverage: lcov not found
```

**Solution**: Install coverage tools:

```bash
# Ubuntu/Debian
sudo apt install lcov

# macOS
brew install lcov

# Windows (via vcpkg)
vcpkg install lcov
```

#### 4. Timeout Errors

```
‚ö†Ô∏è Request timeout, retrying...
```

**Solution**:

- Use a faster model (e.g., `phi3:mini` instead of `llama3.2`)
- Increase timeout in `llm_client.py`
- Check system resources

### Debug Mode

Enable verbose logging by modifying `main.py`:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## üîç Architecture

### Core Components

1. **Main Orchestrator** (`main.py`)

   - Coordinates the entire pipeline
   - Handles file discovery and processing
   - Manages error recovery

2. **LLM Client** (`llm_client.py`)

   - Communicates with Ollama API
   - Implements retry logic and error handling
   - Supports multiple models

3. **Build Utilities** (`build_utils.py`)

   - CMake project building
   - Test execution
   - Coverage generation

4. **YAML Prompts** (`yaml_prompts/`)
   - Structured instructions for LLM
   - Ensures consistent output
   - Configurable behavior

### Data Flow

```
C++ Source Files ‚Üí LLM (initial.yaml) ‚Üí Raw Tests ‚Üí LLM (refine.yaml) ‚Üí Refined Tests ‚Üí Build ‚Üí Coverage Report
```

## üìà Performance

### Benchmarks

- **Test Generation**: ~30-60 seconds per file (depending on model)
- **Build Time**: Varies by project size
- **Coverage Generation**: ~10-30 seconds

### Optimization Tips

1. **Use faster models** for large projects
2. **Process files in parallel** (future enhancement)
3. **Cache build artifacts** between runs
4. **Skip third-party libraries** in file discovery

## ü§ù Contributing

### Development Setup

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

### Code Style

- Follow PEP 8 for Python code
- Use meaningful variable names
- Add docstrings to functions
- Include error handling

## üôè Acknowledgments

- **Ollama** for providing the LLM infrastructure
- **Google Test** for the testing framework
- **CMake** for build system support
- **GNU Coverage Tools** for coverage analysis

## üìû Support

For issues and questions:

1. Check the troubleshooting section
2. Review existing GitHub issues
3. Create a new issue with detailed information
4. Include system details and error logs

---

**Note**: This tool is designed for educational and development purposes. Always review generated tests before using them in production environments.
